{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424744d2-24b4-4fd1-a4b1-f25cad144213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "def get_acts(model, prompts, where):\n",
    "    import torch\n",
    "    from tqdm import tqdm\n",
    "    # The number of layers our model has. GPT2-medium has 24\n",
    "    layers = range(model.cfg.n_layers)\n",
    "\n",
    "    # This is going to hold all of our activations. Notice the shape here: [n_prompts, n_layers, d_model]\n",
    "    data = torch.zeros((len(prompts), len(layers), model.cfg.d_model))\n",
    "\n",
    "    # For every prompt\n",
    "    for i, prompt in tqdm(enumerate(prompts)):\n",
    "        # Do a forward pass with the LLM on said prompt. This function lets us\n",
    "        # cache the activations.\n",
    "        _, activations = model.run_with_cache(prompt)\n",
    "\n",
    "        # For every layer, go through and grab the activation we want at that layer\n",
    "        # The \"[0, -1]\" there is just getting the first batch (we do one batch at a time, this\n",
    "        # could probably be improved) and then the last token at that batch (the last token\n",
    "        # in the residual stream probably (if some literature is correct) contains the \"most\n",
    "        # information\". This is the last token /in the residual stream/, not like \"dog\" in\n",
    "        # \"John has a dog\". We could experiment if this is the right place/token to try but\n",
    "        # that's for another day\n",
    "        for j in layers:\n",
    "            # Store that activation!\n",
    "            data[i, j] = activations[f'blocks.{j}.{where}'][0,-1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da47c75c-fce3-4467-8136-c96360c7721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model Qwen/Qwen2-0.5B into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1020868"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformer_lens\n",
    "import random\n",
    "import torch\n",
    "\n",
    "qwen2_05b = transformer_lens.HookedTransformer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "ds = load_dataset(\"community-datasets/generics_kb\", \"generics_kb_best\")\n",
    "sentences = ds['train']['generic_sentence']\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9749aecd-7265-489b-8f06-ba0f19571fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132d58f6-3a64-46b0-bbef-fba6d7089593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Old men have levels.', 'Birds have eyes.', 'Some people think all power is leadership.', 'Strange creatures spend whole nights in it, at certain seasons of the year.', 'Matter waves arise in quantum mechanical description of nature.', 'Saponins have many gifts to offer the human body in the area of health.', \"Eyes become a deaf person's ears.\", 'Men can have sex.', 'Quality assurance is a plant wide activity involving all departments and individual employees.', 'Most sharks have warm blood.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [25:55, 12.86it/s]\n"
     ]
    }
   ],
   "source": [
    "subset = sentences[0:20_000]\n",
    "print(subset[0:10])\n",
    "\n",
    "where = \"hook_resid_post\"\n",
    "acts = get_acts(qwen2_05b, subset, where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e0a23f-3a4a-46dc-a39b-19cbc9e9cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(acts, f\"qwen2_20k_11162024.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
